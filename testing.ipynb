{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3,5,6\"\n",
    "from chatgpt import run_prompt\n",
    "import spacy\n",
    "import pandas as pd\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "MODEL = \"GPT-4\"\n",
    "model = \"gpt-3.5-turbo-1106\" if MODEL == \"GPT-3.5\" else \"gpt-4-0125-preview\" if MODEL == \"GPT-4\" else None\n",
    "SYSTEM_PROMPT = \"\"\n",
    "dataset = pd.read_csv(\"../data/stitched.tsv\", sep=\"\\t\", header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_answer(prompts):\n",
    "    outputs_raw = llm.generate(prompts, sampling_params)\n",
    "    outputs = []\n",
    "    for o in outputs_raw:\n",
    "        outputs.append(vars(o.outputs[0])[\"text\"].strip())\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_verb_with_throw(sentence_object):\n",
    "    sentence_split = sentence_object['sentence'].split()\n",
    "    doc = nlp(sentence_object['sentence'])\n",
    "    # get tag of original verb\n",
    "    for token_i, token in enumerate(doc):\n",
    "        if token_i == int(sentence_object['verb_i']):\n",
    "            original_verb_tag = token.tag_\n",
    "            break\n",
    "\n",
    "    # now inflect throw to be the same tense as the original verb\n",
    "    if original_verb_tag == 'VBG':\n",
    "        new_verb_form = 'throwing'\n",
    "    elif original_verb_tag == 'VBD':\n",
    "        new_verb_form = 'threw'\n",
    "    elif original_verb_tag == 'VBZ':\n",
    "        new_verb_form = 'throws'\n",
    "    elif original_verb_tag == 'VBP':\n",
    "        new_verb_form = 'throw'\n",
    "    elif original_verb_tag == 'VB':\n",
    "        new_verb_form = 'throw'\n",
    "    elif original_verb_tag == 'VBN':\n",
    "        new_verb_form = 'thrown'\n",
    "    else:\n",
    "        print(f\"Error: verb tag {original_verb_tag} not recognized\")\n",
    "        return None\n",
    "    sentence_split[int(sentence_object['verb_i'])] = new_verb_form\n",
    "    sentence_object['sentence'] = ' '.join(sentence_split)\n",
    "    return sentence_object\n",
    "\n",
    "def get_instruction(sentence_object, sentence_string):\n",
    "    sentence_split = sentence_object['sentence'].split()\n",
    "    doc = nlp(sentence_object['sentence'])\n",
    "    direct_object_lemmatised = sentence_object[\"direct_object\"]\n",
    "    direct_object_unlemmatised = sentence_split[int(sentence_object['direct_object_i'])]\n",
    "    # get tag of original verb\n",
    "    for token_i, token in enumerate(doc):\n",
    "        if token_i == int(sentence_object['direct_object_i']):\n",
    "            original_dobj_tag = token.tag_\n",
    "            break\n",
    "    if original_dobj_tag == 'NNS':\n",
    "        be_form = 'are'\n",
    "        direct_object = direct_object_unlemmatised\n",
    "    elif original_dobj_tag == 'NN':\n",
    "        be_form = 'is'\n",
    "        direct_object = direct_object_unlemmatised\n",
    "    elif original_dobj_tag == 'NNPS':\n",
    "        be_form = 'are'\n",
    "        direct_object = direct_object_unlemmatised\n",
    "    elif original_dobj_tag == 'NNP':\n",
    "        be_form = 'is'\n",
    "        direct_object = direct_object_unlemmatised\n",
    "    elif original_dobj_tag == 'PRP':\n",
    "        if direct_object_lemmatised.lower() in ['it', 'he', 'she']:\n",
    "            be_form = 'is'\n",
    "            direct_object = direct_object_lemmatised\n",
    "        elif direct_object_lemmatised.lower() in ['they', 'we', 'you']:\n",
    "            be_form = 'are'\n",
    "            direct_object = direct_object_lemmatised\n",
    "        elif direct_object_lemmatised.lower() in ['i']:\n",
    "            be_form = 'am'\n",
    "            direct_object = direct_object_lemmatised\n",
    "        elif direct_object_lemmatised.lower() == \"himself\":\n",
    "            be_form = 'is'\n",
    "            direct_object = \"he\"\n",
    "        elif direct_object_lemmatised.lower() == \"herself\":\n",
    "            be_form = 'is'\n",
    "            direct_object = \"she\"\n",
    "        elif direct_object_lemmatised.lower() == \"itself\":\n",
    "            be_form = 'is'\n",
    "            direct_object = \"it\"\n",
    "        elif direct_object_lemmatised.lower() == \"themselves\":\n",
    "            be_form = 'are'\n",
    "            direct_object = \"they\"\n",
    "        elif direct_object_lemmatised.lower() == \"myself\":\n",
    "            be_form = 'am'\n",
    "            direct_object = \"I\"\n",
    "        elif direct_object_lemmatised.lower() == \"yourself\":\n",
    "            be_form = 'are'\n",
    "            direct_object = \"you\"\n",
    "        else:\n",
    "            print(f\"Error: pronoun {direct_object_lemmatised} not recognized\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"{direct_object_unlemmatised} {original_dobj_tag} \")\n",
    "        return None\n",
    "    default_instruction = f\"In the sentence '{sentence_string}', {be_form} {direct_object} moving, yes or no?.\\nAnswer:\"\n",
    "    return default_instruction\n",
    "\n",
    "def parse_system_answer(system_answer):\n",
    "    system_answer = system_answer.lower()\n",
    "    if system_answer[:3] == \"yes\" or \"yes,\" in system_answer or \"the answer is yes\" in system_answer or \"there is an implication that something is moving\" in system_answer or \"it seems that something is moving\" in system_answer or 'the answer is \"yes.\"' in system_answer:\n",
    "        return True\n",
    "    elif system_answer[:2] == \"no\" or \"no,\" in system_answer or \"no explicit indication\" in system_answer or \"the answer is no\" in system_answer or \"there is not an explicit mention of something moving\"  in system_answer or \"it is not explicitly mentioned whether something is moving or not\" or 'the answer is \"no.\"' in system_answer:   \n",
    "        return False\n",
    "    else:\n",
    "        print(system_answer)\n",
    "        return \"invalid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "total_cost = 0\n",
    "results = {\"both_yes\": [], \"both_no\": [], \"from_yes_to_no\": [], \"from_no_to_yes\": []}\n",
    "for sentence_i, sentence in tqdm(dataset.iterrows()):\n",
    "    try:\n",
    "        original_sentence = sentence[\"sentence\"]\n",
    "        replaced_sentence = replace_verb_with_throw(sentence)[\"sentence\"]\n",
    "    except Exception as e:\n",
    "        continue\n",
    "    # print(replaced_sentence)\n",
    "    original_instruction = get_instruction(sentence, original_sentence)\n",
    "    replaced_instruction = get_instruction(sentence, replaced_sentence)\n",
    "    if not original_instruction or not replaced_instruction:\n",
    "        continue\n",
    "    result_original, cost_original = run_prompt(original_instruction,SYSTEM_PROMPT,model)\n",
    "    result_replaced, cost_replaced = run_prompt(replaced_instruction,SYSTEM_PROMPT,model)\n",
    "    total_cost += cost_original + cost_replaced\n",
    "    parsed_result_original = parse_system_answer(result_original)\n",
    "    parsed_result_replaced = parse_system_answer(result_replaced)\n",
    "    if parsed_result_original == \"invalid\" or parsed_result_replaced == \"invalid\":\n",
    "        # print(original_sentence, replaced_sentence, \"invalid\")\n",
    "        continue\n",
    "    else:\n",
    "        if parsed_result_original and parsed_result_replaced:\n",
    "            results[\"both_yes\"].append(sentence)\n",
    "        elif not parsed_result_original and not parsed_result_replaced:\n",
    "            results[\"both_no\"].append(sentence)\n",
    "        elif parsed_result_original and not parsed_result_replaced:\n",
    "            results[\"from_yes_to_no\"].append(sentence)\n",
    "        elif not parsed_result_original and parsed_result_replaced:\n",
    "            results[\"from_no_to_yes\"].append(sentence)\n",
    "                \n",
    "print(f\"Total cost: {total_cost}\")\n",
    "# for all four classes, do a bin count of the verbs\n",
    "for result_class in [\"both_yes\", \"both_no\", \"from_yes_to_no\", \"from_no_to_yes\"]:\n",
    "    print(f\"Class: {result_class}, count: {len(results[result_class])}\")\n",
    "    verb_counts = pd.Series([sentence['verb'] for sentence in results[result_class]]).value_counts()\n",
    "    for verb, count in verb_counts.items():\n",
    "        print(f\"{verb}: {count}\", end=\", \")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "# print a confusion matrix\n",
    "print(f\"Both yes: {len(results['both_yes'])}\")\n",
    "print(f\"Both no: {len(results['both_no'])}\")\n",
    "print(f\"From yes to no: {len(results['from_yes_to_no'])}\")\n",
    "print(f\"From no to yes: {len(results['from_no_to_yes'])}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num = sum([len(results[result_class]) for result_class in [\"both_yes\", \"both_no\", \"from_yes_to_no\", \"from_no_to_yes\"]])\n",
    "print(\"both yes percentage {0:.2f}\".format(len(results[\"both_yes\"])/total_num*100))\n",
    "\n",
    "print(\"from no to yes percentage {0:.2f}\".format(len(results[\"from_no_to_yes\"])/total_num*100))\n",
    "print(\"invalid percentage {0:.2f}\".format((len(results[\"both_no\"])+len(results[\"from_yes_to_no\"]))/total_num*100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
