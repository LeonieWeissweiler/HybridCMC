{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3,5,6\"\n",
    "from chatgpt import run_prompt\n",
    "import spacy\n",
    "import pandas as pd\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "MODEL = \"GPT-3.5\"\n",
    "model = \"gpt-3.5-turbo-1106\" if MODEL == \"GPT-3.5\" else \"gpt-4-0125-preview\" if MODEL == \"GPT-4\" else None\n",
    "SYSTEM_PROMPT = \"\"\n",
    "dataset = pd.read_csv(\"../data/stitched.tsv\", sep=\"\\t\", header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_verb_with_throw(sentence_object):\n",
    "    sentence_split = sentence_object['sentence'].split()\n",
    "    doc = nlp(sentence_object['sentence'])\n",
    "    # get tag of original verb\n",
    "    for token_i, token in enumerate(doc):\n",
    "        if token_i == int(sentence_object['verb_i']):\n",
    "            original_verb_tag = token.tag_\n",
    "            break\n",
    "\n",
    "    # now inflect throw to be the same tense as the original verb\n",
    "    if original_verb_tag == 'VBG':\n",
    "        new_verb_form = 'throwing'\n",
    "    elif original_verb_tag == 'VBD':\n",
    "        new_verb_form = 'threw'\n",
    "    elif original_verb_tag == 'VBZ':\n",
    "        new_verb_form = 'throws'\n",
    "    elif original_verb_tag == 'VBP':\n",
    "        new_verb_form = 'throw'\n",
    "    elif original_verb_tag == 'VB':\n",
    "        new_verb_form = 'throw'\n",
    "    elif original_verb_tag == 'VBN':\n",
    "        new_verb_form = 'thrown'\n",
    "    else:\n",
    "        # print(f\"Error: verb tag {original_verb_tag} not recognized\")\n",
    "        return None\n",
    "    sentence_split[int(sentence_object['verb_i'])] = new_verb_form\n",
    "    sentence_object['sentence'] = ' '.join(sentence_split)\n",
    "    return sentence_object\n",
    "\n",
    "def get_instruction(sentence_object, sentence_string):\n",
    "    sentence_split = sentence_object['sentence'].split()\n",
    "    doc = nlp(sentence_object['sentence'])\n",
    "    direct_object_lemmatised = sentence_object[\"direct_object\"]\n",
    "    direct_object_unlemmatised = sentence_split[int(sentence_object['direct_object_i'])]\n",
    "    # get tag of original verb\n",
    "    for token_i, token in enumerate(doc):\n",
    "        if token_i == int(sentence_object['verb_i']):\n",
    "            original_verb_tag = token.tag_\n",
    "            break\n",
    "    for token_i, token in enumerate(doc):\n",
    "        if token_i == int(sentence_object['direct_object_i']):\n",
    "            original_dobj_tag = token.tag_\n",
    "            break\n",
    "    if original_dobj_tag == 'NNS':\n",
    "        be_form = 'are'\n",
    "        direct_object = direct_object_unlemmatised\n",
    "    elif original_dobj_tag == 'NN':\n",
    "        be_form = 'is'\n",
    "        direct_object = direct_object_unlemmatised\n",
    "    elif original_dobj_tag == 'NNPS':\n",
    "        be_form = 'are'\n",
    "        direct_object = direct_object_unlemmatised\n",
    "    elif original_dobj_tag == 'NNP':\n",
    "        be_form = 'is'\n",
    "        direct_object = direct_object_unlemmatised\n",
    "    elif original_dobj_tag == 'PRP':\n",
    "        if direct_object_lemmatised.lower() in ['it', 'he', 'she']:\n",
    "            be_form = 'is'\n",
    "            direct_object = direct_object_lemmatised\n",
    "        elif direct_object_lemmatised.lower() in ['they', 'we', 'you']:\n",
    "            be_form = 'are'\n",
    "            direct_object = direct_object_lemmatised\n",
    "        elif direct_object_lemmatised.lower() in ['i']:\n",
    "            be_form = 'am'\n",
    "            direct_object = direct_object_lemmatised\n",
    "        elif direct_object_lemmatised.lower() == \"himself\":\n",
    "            be_form = 'is'\n",
    "            direct_object = \"he\"\n",
    "        elif direct_object_lemmatised.lower() == \"herself\":\n",
    "            be_form = 'is'\n",
    "            direct_object = \"she\"\n",
    "        elif direct_object_lemmatised.lower() == \"itself\":\n",
    "            be_form = 'is'\n",
    "            direct_object = \"it\"\n",
    "        elif direct_object_lemmatised.lower() == \"themselves\":\n",
    "            be_form = 'are'\n",
    "            direct_object = \"they\"\n",
    "        elif direct_object_lemmatised.lower() == \"myself\":\n",
    "            be_form = 'am'\n",
    "            direct_object = \"I\"\n",
    "        elif direct_object_lemmatised.lower() == \"yourself\":\n",
    "            be_form = 'are'\n",
    "            direct_object = \"you\"\n",
    "        else:\n",
    "            # print(f\"Error: pronoun {direct_object_lemmatised} not recognized\")\n",
    "            return None\n",
    "    else:\n",
    "        # print(f\"{direct_object_unlemmatised} {original_dobj_tag} \")\n",
    "        return None\n",
    "    default_instruction = f\"In the sentence '{sentence_string}', {be_form} {direct_object} moving, yes or no?.\\nAnswer:\"\n",
    "    return default_instruction\n",
    "\n",
    "def parse_system_answer(system_answer):\n",
    "    system_answer = system_answer.lower()\n",
    "    if system_answer[:3] == \"yes\" or \"yes,\" in system_answer or \"the answer is yes\" in system_answer or \"there is an implication that something is moving\" in system_answer or \"it seems that something is moving\" in system_answer or 'the answer is \"yes.\"' in system_answer:\n",
    "        return True\n",
    "    elif system_answer[:2] == \"no\" or \"no,\" in system_answer or \"no explicit indication\" in system_answer or \"the answer is no\" in system_answer or \"there is not an explicit mention of something moving\"  in system_answer or \"it is not explicitly mentioned whether something is moving or not\" or 'the answer is \"no.\"' in system_answer:   \n",
    "        return False\n",
    "    else:\n",
    "        # print(system_answer)\n",
    "        return \"invalid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "answers_path = None\n",
    "# list all files \n",
    "files = os.listdir(answers_path)\n",
    "for file in files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "import spacy\n",
    "answers_path = None\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "sentences_for_model = []\n",
    "sentence_counter = 0\n",
    "sentence_i_to_sentence_pairs = {}\n",
    "instruction_to_sentence = {}\n",
    "sentence_to_replaced_instruction = {}\n",
    "dataset = pd.read_csv(\"../data/stitched.tsv\", sep=\"\\t\", header=0)\n",
    "for _, sentence in tqdm(dataset.iterrows()):\n",
    "    original_sentence = sentence[\"sentence\"]\n",
    "    replaced_sentence_obj = replace_verb_with_throw(sentence)\n",
    "    if replaced_sentence_obj is None:\n",
    "        continue\n",
    "    replaced_sentence = replaced_sentence_obj[\"sentence\"]\n",
    "    # print(replaced_sentence)\n",
    "    original_instruction = get_instruction(sentence, original_sentence)\n",
    "    replaced_instruction = get_instruction(sentence, replaced_sentence)\n",
    "    if original_instruction  and replaced_instruction:\n",
    "        instruction_to_sentence[original_instruction] = sentence\n",
    "        sentence_to_replaced_instruction[sentence[\"sentence\"]] = replaced_instruction\n",
    "        # sentence_i_to_sentence_pairs[sentence_counter] = {\"original\": original_sentence, \"replaced\": replaced_sentence}\n",
    "        # sentence_counter += 1\n",
    "        sentences_for_model.append(original_instruction)\n",
    "        sentences_for_model.append(replaced_instruction)\n",
    "            \n",
    "# write sentences_for_model to a json file\n",
    "with open('sentences_for_model.json', 'w') as f:\n",
    "    json.dump(sentences_for_model, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# mistralai_Mistral-7B-Instruct-v0.2_model_outputs.json\n",
    "# meta-llama_Llama-2-7b-hf_model_outputs.json\n",
    "# mistralai_Mistral-7B-Instruct-v0.1_model_outputs.json\n",
    "# mistralai_Mistral-7B-v0.1_model_outputs.json\n",
    "# meta-llama_Llama-2-7b-chat-hf_model_outputs.json\n",
    "# meta-llama_Llama-2-13b-hf_model_outputs.json\n",
    "# mistralai_Mixtral-8x7B-Instruct-v0.1_model_outputs.json\n",
    "# gemini_pro_model_outputs.json\n",
    "# TheBloke_Llama-2-70B-AWQ_model_outputs.json\n",
    "# microsoft_phi-2_model_outputs.json\n",
    "# meta-llama_Llama-2-13b-chat-hf_model_outputs.json\n",
    "# mistralai_Mixtral-8x7B-v0.1_model_outputs.json\n",
    "# TheBloke_Llama-2-70B-Chat-AWQ_model_outputs.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "import spacy\n",
    "answers_path = None\n",
    "model_string = 'TheBloke_Llama-2-70B-Chat-AWQ_model_outputs.json'\n",
    "results = {\"both_yes\": [], \"both_no\": [], \"from_yes_to_no\": [], \"from_no_to_yes\": []}\n",
    "# get the model answers\n",
    "model_answers = json.load(open(answers_path + model_string, 'r'))\n",
    "print(len(model_answers))\n",
    "for original_instruction, sentence in instruction_to_sentence.items():\n",
    "    try:\n",
    "        result_original = model_answers[original_instruction]\n",
    "        result_replaced = model_answers[sentence_to_replaced_instruction[sentence[\"sentence\"]]]\n",
    "    except KeyError:\n",
    "        print(f\"Error: sentence {sentence['sentence']} not found\")\n",
    "        continue\n",
    "\n",
    "    parsed_result_original = parse_system_answer(result_original)\n",
    "    parsed_result_replaced = parse_system_answer(result_replaced)\n",
    "    if parsed_result_original == \"invalid\" or parsed_result_replaced == \"invalid\":\n",
    "        print(result_original, result_replaced, \"invalid\")\n",
    "    else:\n",
    "        if parsed_result_original and parsed_result_replaced:\n",
    "            results[\"both_yes\"].append(sentence)\n",
    "        elif not parsed_result_original and not parsed_result_replaced:\n",
    "            results[\"both_no\"].append(sentence)\n",
    "        elif parsed_result_original and not parsed_result_replaced:\n",
    "            results[\"from_yes_to_no\"].append(sentence)\n",
    "        elif not parsed_result_original and parsed_result_replaced:\n",
    "            results[\"from_no_to_yes\"].append(sentence)\n",
    "                \n",
    "# for result_class in [\"both_yes\", \"both_no\", \"from_yes_to_no\", \"from_no_to_yes\"]:\n",
    "#     print(f\"Class: {result_class} {len(results[result_class])}\")\n",
    "#     verb_counts = pd.Series([sentence['verb'] for sentence in results[result_class]]).value_counts()\n",
    "#     print(verb_counts)\n",
    "#     for verb, count in verb_counts.items():\n",
    "#         print(f\"{verb}: {count}\", end=\", \")\n",
    "\n",
    "total_num = sum([len(results[result_class]) for result_class in [\"both_yes\", \"both_no\", \"from_yes_to_no\", \"from_no_to_yes\"]])\n",
    "print(\"both yes percentage {0:.2f}\".format(len(results[\"both_yes\"])/total_num*100))\n",
    "\n",
    "print(\"from no to yes percentage {0:.2f}\".format(len(results[\"from_no_to_yes\"])/total_num*100))\n",
    "print(\"invalid percentage {0:.2f}\".format((len(results[\"both_no\"])+len(results[\"from_yes_to_no\"]))/total_num*100))\n",
    "print(model_string)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Both yes: {len(results['both_yes'])}\")\n",
    "print(f\"Both no: {len(results['both_no'])}\")\n",
    "print(f\"From yes to no: {len(results['from_yes_to_no'])}\")\n",
    "print(f\"From no to yes: {len(results['from_no_to_yes'])}\")\n",
    "\n",
    "total_num = sum([len(results[result_class]) for result_class in [\"both_yes\", \"both_no\", \"from_yes_to_no\", \"from_no_to_yes\"]])\n",
    "print(\"both yes percentage {0:.2f}\".format(len(results[\"both_yes\"])/total_num*100))\n",
    "\n",
    "print(\"from no to yes percentage {0:.2f}\".format(len(results[\"from_no_to_yes\"])/total_num*100))\n",
    "print(\"invalid percentage {0:.2f}\".format((len(results[\"both_no\"])+len(results[\"from_yes_to_no\"]))/total_num*100))\n",
    "print(model_string)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
