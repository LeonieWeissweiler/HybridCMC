{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sentences = [\n",
    "    \"Sam sneezed the napkin off the table.\",\n",
    "    \"Joe squeezed the rubber ball inside the jar.\",\n",
    "    \"She put the phone on the desk.\",\n",
    "    \"Pat pushed the piano into the room.\",\n",
    "    \"Pat ordered him into the room.\",\n",
    "    \"Pat allowed Chris into the room.\",\n",
    "    \"Pat blocked Chris out of the room.\",\n",
    "    \"Pat assisted Chris into the room.\",\n",
    "    \"Pat threw the metal off the table.\",\n",
    "    \"Joe moved it onto the table.\",\n",
    "    \"He threw it towards the door.\",\n",
    "    \"He put it near the table.\",\n",
    "    \"Joe kicked the bottle into the yard.\",\n",
    "    \"They laughed the poor guy out of the room.\",\n",
    "    \"Sue let the water out of the bathtub.\",\n",
    "    \"Sam helped him into the car.\",\n",
    "    \"They sprayed the paint onto the wall.\",\n",
    "    \"Joe kicked the dog into the bathroom.\",\n",
    "    \"Frank squeezed the ball through the crack.\",\n",
    "    \"Sam sawed/tore/hacked/ripped a piece off the block.\",\n",
    "    \"Sam washed/rinsed/cleaned the soap out of her eyes.\",\n",
    "    \"Sam mixed/stirred the paint thinner into the paint.\",\n",
    "    \"The audience laughed the poor guy off of the stage.\",\n",
    "    \"In the last star trek episode, there was a woman who could think people into a different galaxy.\",\n",
    "    \"Fred stuffed the papers in the envelope.\",\n",
    "    \"Sam pushed him within arm's length of the grenade.\",\n",
    "    \"Sam shoved him outside the room.\",\n",
    "    \"Sam urged Bill outside of the house.\",\n",
    "    \"Sam shoved it into the carton.\",\n",
    "    \"Sam invited him out to her cabin.\",\n",
    "    \"Sam beckoned him into the room.\",\n",
    "    \"Sam urged him into the room.\",\n",
    "    \"Sam sent him to the market.\",\n",
    "    \"Sam let Bill into the room.\",\n",
    "    \"Sam blocked Joe out of the house.\",\n",
    "    \"Sam locked him into the bathroom.\",\n",
    "    \"He kept her at arm's length.\",\n",
    "    \"Sam barricaded him out of the room.\",\n",
    "    \"Sam assisted her out of the room.\",\n",
    "    \"Sam guided him through the terrain.\",\n",
    "    \"Sam showed him into the living room.\",\n",
    "    \"Sam walked him to the car.\",\n",
    "    \"Sam accompanied Bob into the room.\",\n",
    "    \"Ann chased the squirrel out of her house.\",\n",
    "    \"Sam coaxed him into the room.\",\n",
    "    \"He hit the ball over the fence.\",\n",
    "    \"Please chop the kindling into the bin provided for it.\",\n",
    "    \"Sam asked him into the room.\",\n",
    "    \"Joe pushed the piano up the stairs.\",\n",
    "    \"The wind blew the ship off course.\",\n",
    "    \"The rain swept the ring into the gutter.\",\n",
    "    \"Sam frightened Bob out of the house.\",\n",
    "    \"Sam lured him into the room.\",\n",
    "    \"Sam invited him onto the deck.\",\n",
    "    \"Sam permitted him out of the house.\",\n",
    "    \"Sam asked Joe into the room.\",\n",
    "    \"Sam ordered Bob into the jail cell.\",\n",
    "    \"The company flew her to Chicago for an interview.\",\n",
    "    \"He hit the ball across the field.\",\n",
    "    \"The butcher sliced the salami onto the wax paper.\",\n",
    "    \"Joey clumped his potatoes into the middle of his plate.\",\n",
    "    \"Joey grated the cheese onto a serving plate.\",\n",
    "    \"Sam shredded the papers into the garbage pail.\",\n",
    "    \"Sam carefully broke the eggs into the bowl.\",\n",
    "    \"He nudged the gold ball into the hole.\",\n",
    "    \"He shoved the cart down the incline.\",\n",
    "    \"Sam frightened Bob away from the door.\",\n",
    "    \"They laughed the poor guy into his car.\",\n",
    "    \"Sam, stop frightening Bobby under the bed.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_sentences = [\n",
    "    'Joe careened into the room with the help of cane.',\n",
    "    'The boat burned into the cave.',\n",
    "    'The bird chirped out of the door.',\n",
    "    'The dog barked into the room.',\n",
    "    'The rooster crowed out of the barn.',\n",
    "    'The man laughed out of room.',\n",
    "    'Joe struck the ball across the field.',\n",
    "    'Sam encouraged him into the room.',\n",
    "    'He struck the ball over the fence.',\n",
    "    'Sam begged him into the room.',\n",
    "    'The hammer broke the vase onto the floor.',\n",
    "    'The hammer broke the vase into pieces.',\n",
    "    'His cane helped him into the car.',\n",
    "    'Sam convinced/persuaded/encouraged/instructed him into the room.',\n",
    "    'Sam pleaded Joe into the room.',\n",
    "    'Farmer Joe grew those vines onto his roof.',\n",
    "    'The invalid owner ran his favorite horse onto the field.',\n",
    "    'The car struck a brick wall into pieces.',\n",
    "    'He filled water into the tub.',\n",
    "    'He covered the blanket over Mary.',\n",
    "    'He nudged the ball down the incline.',\n",
    "    'They laughed the poor guy into his car.',\n",
    "    'Sam frightened Bob under the bed.']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adpositions = ['across', 'at', 'down', 'from', 'in', 'inside', 'into', 'near', 'off', 'off of', 'on', 'onto', 'out of', 'out to', 'outside', 'outside of', 'over', 'through', 'to', 'towards', 'under', 'up', 'within']\n",
    "\n",
    "def check_dobj(i, dependencies, verb):\n",
    "    if i >= len(dependencies):\n",
    "        return None\n",
    "    text, lemma, pos, dep, head, head_i = dependencies[i]\n",
    "\n",
    "    if pos in ['VERB', 'AUX']:\n",
    "        return None\n",
    "    \n",
    "    if dep == 'ROOT':\n",
    "        return None\n",
    "\n",
    "    if dep == 'dobj' and head == verb:\n",
    "        return i\n",
    "\n",
    "    return check_dobj(head_i, dependencies, verb) \n",
    "\n",
    "\n",
    "def check_adp(start_i, dependencies, adpositions): #note that this does not include dependencies because spacy can't be trusted on those\n",
    "    if start_i + 1 < len(dependencies):\n",
    "        longer_adp = dependencies[start_i][0] + \" \" + dependencies[start_i + 1][0]\n",
    "        if longer_adp in adpositions:\n",
    "            return ([start_i, start_i + 1], longer_adp)\n",
    "    \n",
    "    if start_i < len(dependencies) and dependencies[start_i][0] in adpositions:\n",
    "        return ([start_i], dependencies[start_i][1])\n",
    "\n",
    "    return (None, None)\n",
    "\n",
    "def check_pobj(dependencies, adp_index):\n",
    "    pobj_token_list = [(lemma, pobj_i) for pobj_i, (text, lemma, pos, dep, head, head_i) in enumerate(dependencies) if head_i in adp_index and dep == 'pobj' and pos not in ['NUM', 'PUNCT']]\n",
    "    if len(pobj_token_list) > 1:\n",
    "        raise Exception\n",
    "    if len(pobj_token_list) == 1:\n",
    "        return pobj_token_list[0]\n",
    "    return (None, None)\n",
    "\n",
    "# Why     why     SCONJ   advmod  is      1\n",
    "def is_cm(dependencies, nlp, sentence):\n",
    "    for i, (token_text, lemma, pos, dep, head, head_i) in enumerate(dependencies):\n",
    "        if pos == 'VERB':\n",
    "            # Look for a direct object (dobj) immediately following the verb\n",
    "            dobj_i = check_dobj(i + 1, dependencies, token_text)\n",
    "            if dobj_i:\n",
    "                dobj_lemma = dependencies[dobj_i][1]\n",
    "                # Check if the following token is an adposition (ADP) from the list\n",
    "                (adp_index, adp_lemma) = check_adp(dobj_i + 1, dependencies, adpositions)\n",
    "                if adp_index:\n",
    "                    # do another spacy dependency parse\n",
    "                    doc = nlp(sentence)\n",
    "                    dependencies = [(token.text, token.lemma_, token.pos_, token.dep_, token.head.text, token.head.i) for token in doc]\n",
    "                    pobj_lemma, pobj_i = check_pobj(dependencies, adp_index)\n",
    "                    if pobj_lemma:\n",
    "                        result_dict = {'verb': lemma, 'verb_i' : i, 'direct_object': dobj_lemma, 'direct_object_i': dobj_i, 'preposition': adp_lemma, 'preposition_i': adp_index, 'prepositional_object': pobj_lemma, 'prepositional_object_i': pobj_i}\n",
    "                        return result_dict\n",
    "                    # Look for a prepositional object (pobj) child of the adp\n",
    "\n",
    "\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def expand_slashes(sentences):\n",
    "    new_sentences = []\n",
    "    for sentence in sentences:\n",
    "        words = sentence.split()\n",
    "        for i, word in enumerate(words):\n",
    "            if \"/\" in word:\n",
    "                options = word.split(\"/\")\n",
    "                for option in options:\n",
    "                    new_words = words[:i] + [option.strip()] + words[i+1:]\n",
    "                    new_sentence = \" \".join(new_words)\n",
    "                    new_sentences.append(new_sentence)\n",
    "                break\n",
    "        else:\n",
    "            new_sentences.append(sentence)\n",
    "    return new_sentences\n",
    "\n",
    "\n",
    "# Function to perform dependency parsing\n",
    "def dependency_parsing(sentences):\n",
    "    parsed_sentences = []\n",
    "    for sentence in sentences:\n",
    "        doc = nlp(sentence)\n",
    "        dependencies = [(token.text, token.lemma_, token.pos_, token.dep_, token.head.text, token.head.i) for token in doc]\n",
    "        parsed_sentences.append({\"sentence\": sentence, \"dependencies\": dependencies})\n",
    "    return parsed_sentences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_sentences_positive = dependency_parsing(expand_slashes(pos_sentences))\n",
    "processed_sentences_negative = dependency_parsing(expand_slashes(neg_sentences))\n",
    "\n",
    "checked_sentences_positive = [(sentence, is_cm(sentence[\"dependencies\"], nlp, sentence[\"sentence\"])) for sentence in processed_sentences_positive]\n",
    "checked_sentences_negative = [(sentence, is_cm(sentence[\"dependencies\"], nlp, sentence[\"sentence\"])) for sentence in processed_sentences_negative]\n",
    "\n",
    "my_sentences = [\"Just do n't limit it to the last 10 games .\", \"None of my family noticed anything out of the ordinary .\", \"Surely this wastes beer through unnecessary spillages .\",\"Sturridge has missed 74 games through injury in 3 seasons ? !\",\"Refuse to talk politics at work .\"]\n",
    "my_sentences_parsed = dependency_parsing(my_sentences)\n",
    "my_sentences_checked = [(sentence, is_cm(sentence[\"dependencies\"], nlp, sentence[\"sentence\"])) for sentence in my_sentences_parsed]\n",
    "for sentence, result in my_sentences_checked:\n",
    "    if result:\n",
    "        print(sentence[\"sentence\"], end = \"\\t\")\n",
    "        print(f\"{result['verb']}\\t{result['direct_object']}\\t{result['preposition']}\\t{result['prepositional_object']}\\t{result['verb_i']}\\t{result['direct_object_i']}\\t{result['preposition_i']}\\t{result['prepositional_object_i']},1\")\n",
    "for sentence, result in checked_sentences_positive:\n",
    "    if result:\n",
    "        print(sentence[\"sentence\"], end = \"\\t\")\n",
    "        print(f\"{result['verb']}\\t{result['direct_object']}\\t{result['preposition']}\\t{result['prepositional_object']}\\t{result['verb_i']}\\t{result['direct_object_i']}\\t{result['preposition_i']}\\t{result['prepositional_object_i']},1\")\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence, result in checked_sentences_negative:\n",
    "    if result:\n",
    "        print(sentence[\"sentence\"], end = \",\")\n",
    "        print(f\"{result['verb']},{result['direct_object']},{result['preposition']},{result['prepositional_object']},{result['verb_i']},{result['direct_object_i']},{result['preposition_i']},{result['prepositional_object_i']},0\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
